---
layout: archive
title: "Seminar"
permalink: /seminar/
---
<h2>Winter 2024</h2>
<p>1/9: Annoucements and Lightning Talks (Organizers: Yichen, Harvey, Chenghao, Obi and Shester)</p>
<p>1/16: Quiz Bowl (Lead by Harvey Fu)</p>
<p>1/23: [TTIC Talk] Will Merrill: Theoretical Computer Science as a Lens to Understand and Improve Large Language Models</p>
<p>1/27: [TTIC Talk] Ruiqi Zhong: Building Strong Language Models from Weak Validators</p>
<p>1/30: [TTIC Talk] Siddharth Karamcheti: Language-Driven Learning for Interactive Robotics</p>
<p>2/6: Songlin Yang: What's Next for Mamba? Toward More Expressive Recurrent Update Rules</p>

<h2>Autumn 2024</h2>
<p>10/3: Organizational Session</p>
<p>10/4: C&I Welcome Lunch (Organized by Chenghao Yang, supported by faculties)</p>
<p>10/10: Julie Kallini: Mission: Impossible Language Models (Best Paper Award at ACL 2024)</p>
<p>10/18: <a href="https://ci.cs.uchicago.edu/symposium/">Symposium on Communication and Intelligence</a> </p>
<p>10/24: Chenghao Yang: Tutorial on Inference-Time Compute <a href="https://www.youtube.com/watch?v=_Bw5o55SRL8">[video]</a></p>
<p>10/25: [Research at TTIC] Zhewei Sun: Making NLP Systems Robust to Language Variation: The Case of Slang <a href="https://uchicago.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a6c55e8c-fd91-4aee-92ce-b1a901057953">[Panopto Recording]</a> </p>
<p>10/31: Katie Collins: Designing Human-Centric AI with Use in Mind</p>
<p>11/7: Chenghao Yang: Leveraging Large Language Models in Academic Settings: From Architecture to Parameter-Efficient Fine-Tuning and Quantization <a href="https://docs.google.com/presentation/d/1AduB4KWxX_vLuPmHGsy5r2NiGz8o1w7G/edit?usp=sharing&ouid=111912319459945992784&rtpof=true&sd=true">[slides]</a></p>
<p>11/14: Lexing Xie: Topics, Lexicons and Controversies in Daily Moral Dilemmas: What I Learned From /r/AITA</p>
<p>11/21: Julia Watson: Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs</p>
<p>11/28: Thanksgiving</p>
<p>12/5: Mansi Sakarvadia: Mitigating Memorization in Language Models</p>

<h2>Spring 2024</h2>
<p>3/22: Zhewei Sun: Contextualizing Natural Language Agents: The Case of Slang</p>
<p>3/29: Ju-Chieh Chou: AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement</p>
<p>4/5: Jiashuo (Jessie) Wang: Emotion-Aware Dialogues and Beyond</p>
<p>4/12: Hao Peng: Pushing the Boundaries of Length Generalization and Reasoning Capabilities of Open LLMs</p>
<p>4/17: Skipped</p>
<p>4/26: Huan Sun: Powers and Peculiarities of “Reasoning” in Large Language Models and Agents</p>
<p>5/3: Chenghao Yang: Mechanistic Interpretability for Transformers: Compiling Transformer Models into Code <a href="https://docs.google.com/presentation/d/1oIPHP_7qjsrnrDb3kdZIUZt-wQofkiQl/edit?usp=sharing&ouid=111912319459945992784&rtpof=true&sd=true">[slides]</a></p>
<p>5/8: Skipped due to Frontiers of AI in Business and Society workshop in UIC</p>
<p>5/16: Skipped due to finals and conference deadlines</p>
<p>5/24: Mark Yatsker: Inherent Interpretability via Language Model Guided Bottleneck Design</p>


<h2>Winter 2024</h2>
<p>1/5: Hongyuan Mei: Large Language Models as Lego Blocks of Reasoning</p>
<p>1/12: Organizational Session</p>
<p>1/19: Skipped due to TTIC IDEAL Kickoff Workshop</p>
<p>1/26: Denny Zhou: Teach language models to reason</p>
<p>2/2: Mohit Iyyer: Evaluating and detecting long-form LLM-generated text</p>
<p>2/9: Lingyu Gao: Exploring Capabilities of the Generative Components of Pretrained Language Models</p>
<p>2/20: Chenhao Tan: Towards Human-centered AI: How to Generate Useful Explanations for Human-AI Decision Making</p>
<p>2/23: Eunsol Choi: Knowledge-Rich Language Systems in a Dynamic World</p>
<p>3/1: Skipped due to Student Visit Day</p>
<p>3/8: Chenghao Yang: Can You Follow Me? Testing Situational Understanding in ChatGPT</p>


<h2>Fall 2023</h2>

<p>9/29: <a href="https://chicagohai.github.io/news/230813-symposium-hai/">A symposium on Human+AI</a></p>
<p>10/6: Welcome</p>
<p>10/13: David Bau: Locating and editing the knowledge inside large neural models</p>
<p>10/20: Shester Gueuwou: Sign language process</p>
<p>10/27: Nazneen Rajani: Recipe for Training Helpful Chatbots</p>
<p>11/3: Alan Ritter: Towards Cost Efficient Use of Pre-trained Models</p>
<p>11/10: TTIC 20th Anniversary</p>
<p>11/17: Chenghao Yang and Marziyeh Movahedi: LLM inference and finetuning <a href="https://docs.google.com/presentation/d/1AduB4KWxX_vLuPmHGsy5r2NiGz8o1w7G/edit?usp=sharing&ouid=111912319459945992784&rtpof=true&sd=true">[slides]</a></p>
<p>11/24: Thanksgiving</p>
<p>12/1: Ankita Pasad: What do Speech Foundation Models Learn? Analysis and Applications</p>
<p>12/8: Byron Wallace: Interrogating zero- and few-shot learners</p>
